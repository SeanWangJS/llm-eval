# LLM-EVAL

This repo is in purpose of demonstrating how to evaluate a large language model(LLM) with various datasets. For those who are seeking for a framework which support widely models and datasets, please refer to [lm-evaluation-harness](https://github.com/EleutherAI/lm-evaluation-harness). 

